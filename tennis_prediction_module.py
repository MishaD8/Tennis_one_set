#!/usr/bin/env python3
"""
üéæ –ú–û–î–£–õ–¨ –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø –î–õ–Ø –ò–ù–¢–ï–ì–†–ê–¶–ò–ò
–ì–æ—Ç–æ–≤—ã–π –º–æ–¥—É–ª—å –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –≤ –≤–∞—à –ø—Ä–æ–µ–∫—Ç
"""

import pandas as pd
import numpy as np
import joblib
import os
from tensorflow import keras
import warnings
warnings.filterwarnings('ignore')

try:
    from adaptive_ensemble_optimizer import (
        get_ensemble_optimizer, get_optimized_weights, 
        record_model_predictions, init_ensemble_optimizer
    )
    ADAPTIVE_OPTIMIZER_AVAILABLE = True
except ImportError:
    ADAPTIVE_OPTIMIZER_AVAILABLE = False

class TennisPredictionService:
    """
    –°–µ—Ä–≤–∏—Å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–Ω–Ω–∏—Å–Ω—ã—Ö –º–∞—Ç—á–µ–π
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∞—à–∏ –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, models_dir="tennis_models", use_adaptive_weights=True):
        self.models_dir = models_dir
        self.models = {}
        self.scaler = None
        self.expected_features = []
        self.use_adaptive_weights = use_adaptive_weights and ADAPTIVE_OPTIMIZER_AVAILABLE
        
        # Load base weights from metadata if available
        self.base_weights = self._load_base_weights()
        
        # Current ensemble weights (will be updated by adaptive optimizer)
        self.ensemble_weights = self.base_weights.copy()
        
        self.is_loaded = False
        
        # Initialize adaptive optimizer if available
        if self.use_adaptive_weights:
            try:
                if not get_ensemble_optimizer():
                    init_ensemble_optimizer(self.base_weights)
                print("üß† Adaptive ensemble optimization enabled")
            except Exception as e:
                print(f"‚ö†Ô∏è Could not initialize adaptive optimizer: {e}")
                self.use_adaptive_weights = False
    
    def _load_base_weights(self):
        """Load base ensemble weights from metadata file"""
        try:
            metadata_path = os.path.join(self.models_dir, 'metadata.json')
            if os.path.exists(metadata_path):
                import json
                with open(metadata_path, 'r') as f:
                    metadata = json.load(f)
                    weights = metadata.get('ensemble_weights', {})
                    print(f"üìä Loaded base weights from metadata: {weights}")
                    return weights
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load weights from metadata: {e}")
        
        # Fallback to hardcoded weights
        return {
            'neural_network': 0.2054,
            'xgboost': 0.2027,
            'random_forest': 0.1937,
            'gradient_boosting': 0.1916,
            'logistic_regression': 0.2065
        }
    
    def _get_current_weights(self, match_context=None):
        """Get current weights (adaptive or base)"""
        if self.use_adaptive_weights:
            try:
                adaptive_weights = get_optimized_weights(match_context)
                if adaptive_weights:
                    return adaptive_weights
            except Exception as e:
                print(f"‚ö†Ô∏è Error getting adaptive weights: {e}")
        
        return self.ensemble_weights
        
    def load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            print("üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∫–∞–ª–µ—Ä
            scaler_path = os.path.join(self.models_dir, 'scaler.pkl')
            if not os.path.exists(scaler_path):
                raise FileNotFoundError(f"–°–∫–∞–ª–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {scaler_path}")
            self.scaler = joblib.load(scaler_path)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
            model_files = {
                'neural_network': 'neural_network.h5',
                'xgboost': 'xgboost.pkl', 
                'random_forest': 'random_forest.pkl',
                'gradient_boosting': 'gradient_boosting.pkl',
                'logistic_regression': 'logistic_regression.pkl'
            }
            
            loaded_count = 0
            for model_name, filename in model_files.items():
                filepath = os.path.join(self.models_dir, filename)
                if os.path.exists(filepath):
                    try:
                        if model_name == 'neural_network':
                            self.models[model_name] = keras.models.load_model(filepath)
                        else:
                            self.models[model_name] = joblib.load(filepath)
                        loaded_count += 1
                    except Exception as e:
                        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {model_name}: {e}")
                else:
                    print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
            
            if loaded_count == 0:
                raise Exception("–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–∂–∏–¥–∞–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            if 'random_forest' in self.models:
                self.expected_features = list(self.models['random_forest'].feature_names_in_)
            elif 'xgboost' in self.models:
                self.expected_features = list(self.models['xgboost'].feature_names_in_)
            else:
                # Fallback –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Å–ø–∏—Å–∫—É
                self.expected_features = [
                    'player_rank', 'player_age', 'opponent_rank', 'opponent_age',
                    'player_recent_win_rate', 'player_form_trend', 'player_surface_advantage',
                    'h2h_win_rate', 'total_pressure', 'rank_difference', 'rank_ratio',
                    'combined_form', 'surface_pressure_interaction'
                ]
            
            self.is_loaded = True
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} –º–æ–¥–µ–ª–µ–π")
            print(f"üîß –û–∂–∏–¥–∞–µ—Ç—Å—è {len(self.expected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            return False
    
    def create_engineered_features(self, match_data):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        enhanced_data = match_data.copy()
        
        # 1. –†–∞–∑–Ω–æ—Å—Ç—å –∏ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
        enhanced_data['rank_difference'] = enhanced_data['opponent_rank'] - enhanced_data['player_rank']
        enhanced_data['rank_ratio'] = enhanced_data['player_rank'] / (enhanced_data['opponent_rank'] + 1)
        
        # 2. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞
        enhanced_data['combined_form'] = (enhanced_data['player_recent_win_rate'] * 0.7 + 
                                        enhanced_data['h2h_win_rate'] * 0.3)
        
        # 3. –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –ø–æ–∫—Ä—ã—Ç–∏—è –∏ –¥–∞–≤–ª–µ–Ω–∏—è
        enhanced_data['surface_pressure_interaction'] = (enhanced_data['player_surface_advantage'] * 
                                                       enhanced_data['total_pressure'])
        
        return enhanced_data
    
    def validate_input_data(self, match_data):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        required_fields = [
            'player_rank', 'player_age', 'opponent_rank', 'opponent_age',
            'player_recent_win_rate', 'player_form_trend',
            'player_surface_advantage', 'h2h_win_rate', 'total_pressure'
        ]
        
        missing_fields = [field for field in required_fields if field not in match_data]
        if missing_fields:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è: {missing_fields}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
        if not (1 <= match_data['player_rank'] <= 1000):
            raise ValueError("player_rank –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ 1000")
        if not (1 <= match_data['opponent_rank'] <= 1000):
            raise ValueError("opponent_rank –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ 1000")
        if not (0 <= match_data['player_recent_win_rate'] <= 1):
            raise ValueError("player_recent_win_rate –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 0 –¥–æ 1")
        
        return True
    
    def predict_match(self, match_data, return_details=True):
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Args:
            match_data (dict): –î–∞–Ω–Ω—ã–µ –º–∞—Ç—á–∞ —Å 9 –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏ –ø–æ–ª—è–º–∏
            return_details (bool): –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        
        if not self.is_loaded:
            if not self.load_models():
                raise Exception("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        self.validate_input_data(match_data)
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            enhanced_data = self.create_engineered_features(match_data)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å –Ω—É–∂–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            features_df = pd.DataFrame([enhanced_data])
            features_df = features_df[self.expected_features]
            
            # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
            features_df = features_df.fillna(features_df.median())
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∏ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
            X_scaled = self.scaler.transform(features_df)
            
            # Prepare match context for adaptive weights
            match_context = {
                'surface': match_data.get('surface', ''),
                'tournament_importance': enhanced_data.get('total_pressure', 0),
                'rank_difference': enhanced_data.get('rank_difference', 0),
                'match_info': {
                    'player_rank': match_data.get('player_rank'),
                    'opponent_rank': match_data.get('opponent_rank'),
                    'h2h_win_rate': match_data.get('h2h_win_rate')
                }
            }
            
            # Get current weights (adaptive or base)
            current_weights = self._get_current_weights(match_context)
            
            # –ü—Ä–æ–≥–Ω–æ–∑—ã –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            individual_predictions = {}
            
            for model_name, model in self.models.items():
                try:
                    if model_name == 'neural_network':
                        pred = float(model.predict(X_scaled, verbose=0)[0][0])
                    elif model_name == 'logistic_regression':
                        pred = float(model.predict_proba(X_scaled)[0, 1])
                    else:
                        pred = float(model.predict_proba(features_df)[0, 1])
                    
                    individual_predictions[model_name] = pred
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
                    individual_predictions[model_name] = 0.5
            
            # –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
            ensemble_pred = sum(pred * current_weights.get(name, 0.2) 
                               for name, pred in individual_predictions.items())
            total_weight = sum(current_weights.get(name, 0.2) 
                              for name in individual_predictions.keys())
            ensemble_pred /= total_weight if total_weight > 0 else 1
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            if ensemble_pred >= 0.7:
                confidence = "High"
                confidence_ru = "–í—ã—Å–æ–∫–∞—è"
            elif ensemble_pred >= 0.55:
                confidence = "Medium" 
                confidence_ru = "–°—Ä–µ–¥–Ω—è—è"
            else:
                confidence = "Low"
                confidence_ru = "–ù–∏–∑–∫–∞—è"
            
            # –ë–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                'probability': round(ensemble_pred, 4),
                'confidence': confidence,
                'confidence_ru': confidence_ru,
                'recommendation': self._get_recommendation(ensemble_pred, match_data)
            }
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if return_details:
                result.update({
                    'individual_predictions': {
                        name: round(pred, 4) for name, pred in individual_predictions.items()
                    },
                    'key_factors': self._analyze_key_factors(match_data, ensemble_pred),
                    'model_weights': self.ensemble_weights,
                    'input_data': match_data
                })
            
            return result
            
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
    
    def _get_recommendation(self, probability, match_data):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        if probability >= 0.7:
            return "Strong recommendation: High probability of winning at least one set"
        elif probability >= 0.55:
            return "Moderate recommendation: Consider additional factors"
        else:
            return "Caution: Low probability, possible underdog scenario"
    
    def _analyze_key_factors(self, match_data, prediction):
        """–ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤"""
        factors = []
        
        if match_data['player_recent_win_rate'] > 0.8:
            factors.append("Excellent current form")
        
        rank_diff = match_data['opponent_rank'] - match_data['player_rank']
        if rank_diff > 20:
            factors.append(f"Significant ranking advantage (+{rank_diff})")
        elif rank_diff < -10:
            factors.append(f"Playing against higher ranked opponent ({rank_diff})")
        
        if match_data['player_surface_advantage'] > 0.1:
            factors.append("Strong surface advantage")
        elif match_data['player_surface_advantage'] < -0.05:
            factors.append("Surface disadvantage")
        
        if match_data['h2h_win_rate'] > 0.7:
            factors.append("Dominates head-to-head")
        elif match_data['h2h_win_rate'] < 0.4:
            factors.append("Poor head-to-head record")
        
        if match_data['player_form_trend'] > 0.1:
            factors.append("Rising form trend")
        elif match_data['player_form_trend'] < -0.1:
            factors.append("Declining form trend")
        
        return factors
    
    def predict_multiple_matches(self, matches_list):
        """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–∞—Ç—á–µ–π"""
        results = []
        
        for i, match_data in enumerate(matches_list):
            try:
                prediction = self.predict_match(match_data, return_details=False)
                prediction['match_id'] = i
                results.append(prediction)
            except Exception as e:
                results.append({
                    'match_id': i,
                    'error': str(e),
                    'probability': None
                })
        
        return results
    
    def get_model_info(self):
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö"""
        if not self.is_loaded:
            return {"status": "Models not loaded"}
        
        return {
            "status": "loaded",
            "models_count": len(self.models),
            "models": list(self.models.keys()),
            "expected_features": self.expected_features,
            "ensemble_weights": self.ensemble_weights,
            "adaptive_weights_enabled": self.use_adaptive_weights
        }
    
    def record_match_result(self, match_data, predictions_result, actual_result, match_info=None):
        """
        Record actual match result for adaptive weight optimization
        
        Args:
            match_data: Original match data used for prediction
            predictions_result: Result from predict_match() containing individual predictions
            actual_result: Actual match outcome (0 or 1)
            match_info: Additional match information
        """
        if not self.use_adaptive_weights:
            return False
        
        try:
            individual_predictions = predictions_result.get('individual_predictions', {})
            if individual_predictions and ADAPTIVE_OPTIMIZER_AVAILABLE:
                record_model_predictions(
                    individual_predictions, 
                    actual_result, 
                    match_info or match_data
                )
                print(f"üìä Recorded match result for adaptive optimization")
                return True
        except Exception as e:
            print(f"‚ö†Ô∏è Error recording match result: {e}")
        
        return False
    
    def get_ensemble_performance_report(self):
        """Get detailed ensemble performance report"""
        if not self.use_adaptive_weights or not ADAPTIVE_OPTIMIZER_AVAILABLE:
            return {
                'error': 'Adaptive ensemble optimization not available',
                'current_weights': self.ensemble_weights,
                'base_weights': self.base_weights
            }
        
        try:
            from adaptive_ensemble_optimizer import get_ensemble_performance_report
            return get_ensemble_performance_report()
        except Exception as e:
            return {'error': f'Could not get performance report: {e}'}
    
    def update_ensemble_weights(self, context=None):
        """Manually update ensemble weights based on current performance"""
        if not self.use_adaptive_weights:
            return False
        
        try:
            new_weights = self._get_current_weights(context)
            if new_weights:
                self.ensemble_weights = new_weights
                print(f"üîÑ Updated ensemble weights: {new_weights}")
                return True
        except Exception as e:
            print(f"‚ö†Ô∏è Error updating weights: {e}")
        
        return False


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —É–¥–æ–±–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

def create_match_data(player_rank, opponent_rank, player_age=25, opponent_age=25,
                     player_recent_win_rate=0.7, player_form_trend=0.0,
                     player_surface_advantage=0.0, h2h_win_rate=0.5, total_pressure=2.5):
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –º–∞—Ç—á–∞
    
    Args:
        player_rank (int): –†–µ–π—Ç–∏–Ω–≥ –∏–≥—Ä–æ–∫–∞
        opponent_rank (int): –†–µ–π—Ç–∏–Ω–≥ —Å–æ–ø–µ—Ä–Ω–∏–∫–∞
        player_age (int): –í–æ–∑—Ä–∞—Å—Ç –∏–≥—Ä–æ–∫–∞
        opponent_age (int): –í–æ–∑—Ä–∞—Å—Ç —Å–æ–ø–µ—Ä–Ω–∏–∫–∞
        player_recent_win_rate (float): –í–∏–Ω—Ä–µ–π—Ç –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –º–∞—Ç—á–∞—Ö (0-1)
        player_form_trend (float): –¢—Ä–µ–Ω–¥ —Ñ–æ—Ä–º—ã (-0.5 –¥–æ 0.5)
        player_surface_advantage (float): –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –Ω–∞ –ø–æ–∫—Ä—ã—Ç–∏–∏ (-0.3 –¥–æ 0.3)
        h2h_win_rate (float): –í–∏–Ω—Ä–µ–π—Ç –≤ –æ—á–Ω—ã—Ö –≤—Å—Ç—Ä–µ—á–∞—Ö (0-1)
        total_pressure (float): –î–∞–≤–ª–µ–Ω–∏–µ —Ç—É—Ä–Ω–∏—Ä–∞ (1-5)
    
    Returns:
        dict: –î–∞–Ω–Ω—ã–µ –º–∞—Ç—á–∞ –≥–æ—Ç–æ–≤—ã–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    return {
        'player_rank': float(player_rank),
        'opponent_rank': float(opponent_rank),
        'player_age': float(player_age),
        'opponent_age': float(opponent_age),
        'player_recent_win_rate': float(player_recent_win_rate),
        'player_form_trend': float(player_form_trend),
        'player_surface_advantage': float(player_surface_advantage),
        'h2h_win_rate': float(h2h_win_rate),
        'total_pressure': float(total_pressure)
    }

def quick_predict(player_rank, opponent_rank, models_dir="tennis_models", **kwargs):
    """
    –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞ —Å–µ—Ä–≤–∏—Å–∞
    
    Args:
        player_rank (int): –†–µ–π—Ç–∏–Ω–≥ –∏–≥—Ä–æ–∫–∞
        opponent_rank (int): –†–µ–π—Ç–∏–Ω–≥ —Å–æ–ø–µ—Ä–Ω–∏–∫–∞
        models_dir (str): –ü–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—è–º–∏
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–∞—Ç—á–∞
    
    Returns:
        dict: –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    service = TennisPredictionService(models_dir)
    match_data = create_match_data(player_rank, opponent_rank, **kwargs)
    return service.predict_match(match_data)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üéæ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–£–õ–Ø –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 50)
    
    # –ü—Ä–∏–º–µ—Ä 1: –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–Ω–æ–∑
    print("üìä –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–Ω–æ–∑:")
    result = quick_predict(
        player_rank=1, 
        opponent_rank=45,
        player_recent_win_rate=0.85,
        player_surface_advantage=0.12,
        h2h_win_rate=0.75
    )
    print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {result['probability']:.1%}")
    print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence_ru']}")
    
    # –ü—Ä–∏–º–µ—Ä 2: –î–µ—Ç–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    print(f"\nüìä –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:")
    service = TennisPredictionService()
    
    match_data = create_match_data(
        player_rank=5,
        opponent_rank=6,
        player_recent_win_rate=0.72,
        player_form_trend=0.02,
        h2h_win_rate=0.58,
        total_pressure=3.8
    )
    
    result = service.predict_match(match_data)
    
    print(f"–ü—Ä–æ–≥–Ω–æ–∑: {result['probability']:.1%}")
    print(f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {result['recommendation']}")
    print(f"–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã: {result['key_factors']}")
    
    # –ü—Ä–∏–º–µ—Ä 3: –ù–µ—Å–∫–æ–ª—å–∫–æ –º–∞—Ç—á–µ–π
    print(f"\nüìä –ü—Ä–æ–≥–Ω–æ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–∞—Ç—á–µ–π:")
    matches = [
        create_match_data(1, 45, player_recent_win_rate=0.85),
        create_match_data(5, 6, player_recent_win_rate=0.72),
        create_match_data(35, 8, player_recent_win_rate=0.88, player_surface_advantage=0.18)
    ]
    
    results = service.predict_multiple_matches(matches)
    for i, result in enumerate(results, 1):
        if 'probability' in result and result['probability'] is not None:
            print(f"–ú–∞—Ç—á {i}: {result['probability']:.1%} ({result['confidence_ru']})")
        else:
            print(f"–ú–∞—Ç—á {i}: –û—à–∏–±–∫–∞ - {result.get('error', 'Unknown error')}")
    
    print("\n‚úÖ –ú–æ–¥—É–ª—å –≥–æ—Ç–æ–≤ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏!")